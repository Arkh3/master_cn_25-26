{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# plotting libraries\n",
    "\n",
    "# for inline plots in jupyter\n",
    "if True:\n",
    "    %matplotlib inline\n",
    "else:\n",
    "    %matplotlib notebook\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from IPython.display import Math, Latex\n",
    "from IPython.core.display import Image\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "######################### Utilities functions ########################333\n",
    "\n",
    "\n",
    "def combine_edges( counts, edges, threshold ):\n",
    "    '''Manipulate a histogram of data merging bins whose counts are less than\n",
    "    a given threshold\n",
    "    \n",
    "    Example:\n",
    "        import nump as np\n",
    "        \n",
    "        counts, edges  = np.histogram (sample_post, bins=20, density=False)\n",
    "        c, e = combine_edges (count, edges, 6)\n",
    "    '''\n",
    "    \n",
    "    max_ix = counts.argmax()\n",
    "    c_list = list( counts )   # Lists can be popped from\n",
    "    e_list = list( edges )    # Lists can be popped from\n",
    "\n",
    "    def eliminate_left( ix ):\n",
    "        # Sum the count and eliminate the edge relevant to ix\n",
    "        # Before the peak (max_ix)\n",
    "        nonlocal max_ix\n",
    "        max_ix -= 1         # max_ix will change too.\n",
    "        c_list[ix+1]+=c_list[ix]\n",
    "        c_list.pop(ix)\n",
    "        e_list.pop(ix+1)\n",
    "\n",
    "    def eliminate_right( ix ):\n",
    "        # Sum the count and eliminate the edge relevant to ix\n",
    "        # after the peak (max_ix) \n",
    "        c_list[ix-1]+=c_list[ix]\n",
    "        c_list.pop(ix)\n",
    "        e_list.pop(ix)\n",
    "\n",
    "    def last_lt():\n",
    "        # Find the last ix less than the threshold\n",
    "        for ix, ct in zip( range(len(c_list)-1, max_ix, -1), c_list[::-1]):\n",
    "            # ix reduces from len(c_list)-1, c_list is accessed in reverse order.\n",
    "            if ct < threshold:\n",
    "                return ix\n",
    "        return -1  # If no items < threshold return -1\n",
    "\n",
    "    cont = True\n",
    "\n",
    "    def first_lt():\n",
    "        result = -1  # Set default\n",
    "        for ix, ct in enumerate( c_list[:max_ix] ):\n",
    "            if ct < threshold:\n",
    "                result = ix  # If ct < threshold set result to ix\n",
    "            break        # Break out of the loop\n",
    "        return result\n",
    "\n",
    "    cont = True\n",
    "    while cont:\n",
    "        # Each iteration removes any counts less than threshold\n",
    "        # before the peak.  This process would combine e.g. counts of [...,1,2,3,...] into [..., 6, ...]\n",
    "        ix = first_lt()\n",
    "        if ix < 0:\n",
    "            cont = False   # If first_lt returns -1 stop while loop\n",
    "        else:\n",
    "            eliminate_left( ix )\n",
    "\n",
    "    cont = True\n",
    "    while cont:\n",
    "        ix = last_lt()\n",
    "        if ix < 0:\n",
    "            cont = False   # If last_lt returns -1 stop while loop\n",
    "        else:\n",
    "            eliminate_right( ix )\n",
    "\n",
    "    return np.array( c_list ), np.array( e_list )\n",
    "\n",
    "\n",
    "def get_bin_probabilities (distribution, args, edges) :\n",
    "    cdf = distribution.cdf (e,*H0_args)\n",
    "    prob = cdf[1:] - cdf[:-1]\n",
    "    prob[-1] = prob[-1] + (1-cdf[-1])\n",
    "    prob[0]  = prob[0] + cdf[0]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicación de Métodos de Monte Carlo a la Computación Bayesiana**\n",
    "\n",
    "# Inferencia Bayesiana (Teorema de Bayes)\n",
    "\n",
    "En un *enfoque bayesiano* de la estadística, un parámetro $\\theta$ se considera una variable aleatoria con una determinada distribución de probabilidad.\n",
    "El teorema de Bayes relaciona la información inicial que se tiene del parámetro $\\theta$ antes de realizar un experimento y la información que se dispone de él después de realizar el experimento.   \n",
    "\n",
    "* La información inicial que se tiene sobre $\\theta$ se representa mediante su *distribución a priori,*  $\\pi(\\theta)$.\n",
    "\n",
    "* La información que se tiene de $\\theta$ después de realizar uno (o varios) experimento/s, $x$, se codifica mediante su *distribución a posteriori*  $\\pi(\\theta | x)$. \n",
    "\n",
    "* El teorema de Bayes nos permite obtener la densidad de probabilidad $\\pi(\\theta | x)$ en función del resultado del experimento y la densidad de probabilidad a priori $\\pi(\\theta)$. Es, por tanto, un **método general de inducción** o de **aprendizaje a partir de la experiencia:**\n",
    "  $$\\texttt{a priori} \\rightarrow \\texttt{datos} \\rightarrow \\texttt{a posteriori}$$\n",
    "\n",
    "$$\n",
    "\\pi(\\theta | x) = \\frac{ \\pi(x | \\theta) }\n",
    "{ \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta} \n",
    "\\; \\pi(\\theta)\n",
    "$$\n",
    "\n",
    "* La cantidad  $\\pi(x | \\theta)$ del numerador se denomina *verosimilitud* (*likelihood*). Es una **función**  proporcional a la probabilidad de observar el resultado del experimento $x$ (muestra) _para un valor dado_ del parámetro $\\theta$\n",
    "\n",
    "    $$\n",
    "    \\pi(x | \\theta) = \\prod_i f(x_i | \\theta) \n",
    "    $$\n",
    "\n",
    "    siendo $x_i$ con $i=1, \\ldots, n$ los resultados del experimento (valores muestrales) y  $f(x_i | \\theta)$ sus probabilidades para un determinado valor de $\\theta$. (_Como de versomil, esto es, probable, era observar el experimento $x$ dado el valor concreto de $\\theta$_)\n",
    "\n",
    "* El denominador $ \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta$, una vez realizada la integración, **obviamente no** depende del parámetro $\\theta$. Es una constante de normalización para que la integral de $f(\\theta|x)$ sea la unidad.\n",
    "  No proporciona, por tanto, ninguna información adicional sobre la distribución a posteriori.\n",
    "  Algunos autores la denominan **verosimilitud marginal** (o ponderada) ya que es una ponderación de las funciones $f(x|\\theta)$ cuyos coeficientes de ponderación (el peso dado a cada valor  $\\theta$) están dados por la distribución a priori $\\pi (\\theta)$. \n",
    "\n",
    "* Para realizar previsiones se utilizan *distribuciones predictivas* (valor esperado de una determinada función)\n",
    "\n",
    "    $$\n",
    "    E[ g(y|x) ] = \\int g(y| \\theta) \\;  \\pi(\\theta | x)  \\; d\\theta\n",
    "    $$\n",
    "\n",
    "    Por ejemplo, es habitual usar como *predictor* del valor de la v.a $\\theta$ su valor esperado:\n",
    "$$\n",
    "\\widehat{\\theta} = \\int \\theta \\;  \\pi(\\theta | x)  \\; d\\theta\n",
    "$$\n",
    "\n",
    "* Cuando las distribuciones a priori y a posteriori pertenecen a la misma familia se dice que son **_conjugadas a priori_**. A menudo esto implica grandes beneficios desde el punto de vista computacional. \n",
    "* La descripción formal de la inferencia bayesiana es sencilla, sin embargo su implementación **habitualmente no es fácil** y requiere Métodos de Monte Carlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "<div class=\"alert-warning\">\n",
    "\n",
    "\n",
    "Estimar la probabilidad de que un paciente ingresado en planta acabe en la UCI. \n",
    "\n",
    "Para realizar este problema mediante inferencia Bayesiana debemos tener en cuenta:\n",
    "\n",
    "* La probabilidad de que un paciente ingresado en planta acabe en la UCI será nuestro parámetro $\\theta$. Como hemos visto, en el enfoque bayesiano debemos considerar que $\\theta$ es una variable aleatoria.\n",
    "\n",
    "* Debemos conocer la distribución de la v.a $\\theta$ **antes** de realizar el experimento, es decir su *densidad de probabilidad a priori* $\\pi(\\theta)$. Supongamos, por ejemplo, que $\\pi(\\theta)$ se distribuye según una distribución Beta, $\\pi(\\theta) = B(\\theta | \\alpha = 5, \\beta = 10)$.\n",
    "\n",
    "\n",
    "* En el enfoque bayesiano debemos **incorporar la información que nos aporta el resultado de un experimento**. Considerad el siguiente experimento: se contabiliza cuantos de los pacientes que había en planta, $n$, han debido ingresar en la UCI, $k$, después de un determinado periodo de tiempo. Se observa que de los $n=20$ pacientes, uno, $k=1$, debió ingresar en la UCI. \n",
    "\n",
    "    * Debemos calcular la función de verosimilitud  $\\pi(x | \\theta)$ del resultado del experimento. La función de verosimilitud será proporcional a la probabilidad de observar el resultado del experimento en función del valor de $\\theta$: \n",
    "\n",
    "    $$\n",
    "    \\pi(x | \\theta) \\propto \\theta^k (1-\\theta)^{n-k} \n",
    "    $$\n",
    "    \n",
    "    donde, en nuestro experimento, $n=20$ y $k=1$. Notad como en la ecuación anterior $\\pi(x|\\theta)$ **no** está normalizada. \n",
    "    \n",
    "\n",
    "* Debemos elegir un *predictor* adecuado a nuestro problema. Como predictor de $\\theta$ *la probabilidad de que un paciente de la planta acabe en la UCI* utilizaremos su valor esperado $E[\\theta]$. Nos preguntarnos entonces:\n",
    "\n",
    "    1. ¿Cuál es el valor de $E[\\theta]$ **antes** de realizar el experimento? \n",
    "    2. ¿Cuál es el valor de $E[\\theta]$ **después** de observar el resultado del experimento? \n",
    "    \n",
    " </div>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Ayuda:**\n",
    " \n",
    " * Recuerda la distribución  $Beta(\\theta| \\alpha, \\beta)$:\n",
    "   \\begin{align}\n",
    "   Beta(\\theta| \\alpha, \\beta) & = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha -1} (1-\\theta)^{\\beta -1}\n",
    "   \\end{align}\n",
    "   donde $B(\\alpha, \\beta)$ es la constante de normalización, cuyo valor s , en este caso, la función beta:\n",
    "   \\begin{align}\n",
    "   B(\\alpha, \\beta) & = \\frac{\\Gamma (\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\n",
    "   \\end{align}\n",
    "  Observar que la distribución uniforme, $U(0, 1)$, es un caso particular de la distribución $Beta$ cuando $Beta(\\theta| \\alpha=1, \\beta=1)$:\n",
    "\n",
    " * La pregunta (1) es fácil. Al ser la distribución a priori $\\pi(\\theta)$ la distribución $Beta$, su valor esperado será\n",
    " $$\n",
    " \\mu_{\\text{prior}} = E[\\theta]_{\\text{prior}} = \\int_{-\\infty}^{\\infty} \\theta  \\; B(\\theta | \\alpha, \\beta) \\;  d\\theta =  \\frac{\\alpha}{\\alpha + \\beta}\n",
    " $$\n",
    " \n",
    " * Para la pregunta (2) se debe calcular: \n",
    " $$\n",
    " \\mu_{\\text{posterior}}= E[\\theta]_{\\text{posterior}} = \\int_{-\\infty}^{\\infty} \\theta \\;  \\pi(\\theta | x)  \\; d\\theta \n",
    " $$\n",
    "    Para ello se necesita conocer la distribución a posteriori $\\pi(\\theta | x)$. Utilizando el teorema de Bayes, tras re-ordenar términos se obtiene:\n",
    "    \\begin{align}\n",
    " E[\\theta]_{\\text{posterior}} &= \n",
    " \\int_{-\\infty}^{\\infty} \\theta \\;  \\pi(\\theta | x)  \\; d\\theta \\\\\n",
    "                 &= \\int_{-\\infty}^{\\infty} \\theta \\;     \n",
    "\\frac{ \\pi(x | \\theta) \\; \\pi(\\theta) }\n",
    "{ \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta} \n",
    "  \\;  d\\theta  = \n",
    "  \\frac{ \\int_{-\\infty}^{\\infty} \\theta  \\; \\pi(x | \\theta) \\; \\pi(\\theta) \\;  d\\theta }\n",
    "       { \\int_{-\\infty}^{\\infty}            \\pi(x | \\theta) \\; \\pi(\\theta) \\; d\\theta} \\\\\n",
    " &= \\frac{\\int_{-\\infty}^{\\infty} \\theta  \\; \\theta^k (1-\\theta)^{n-k}  \\; \\; \\pi(\\theta) \\; d\\theta }\n",
    " { \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\; \\pi(\\theta) \\; d\\theta}  =\n",
    " \\frac{ \\int_{0}^{1}  \\; \\theta^{k+1} (1-\\theta)^{n-k}  \\; \\; B(\\theta| \\alpha=5, \\beta=10) \\; d\\theta }\n",
    " { \\int_{0}^{1}   \\theta^{k} (1-\\theta)^{n-k} \\; B(\\theta| \\alpha=5, \\beta=10) \\; d\\theta} \n",
    "   \\end{align}\n",
    "  donde se han substiuído los valores de $\\pi(\\theta)$ y de la verosimilitud $\\pi(x|\\theta)$.\n",
    "  \n",
    "   Sino supiésemos resolver analíticamente las integrales anteriores (en este caso sí hay solución analítica aunque no es fácil) podemos **estimar** el numerador y el denominador mediante integración de Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución analítica: aplicación teorema de Bayes\n",
    "\n",
    "En el problema se sugiere utilizar una estrategia de Monte Carlo para estimar el valor esperado de la distribución de probabilidad *a posteriori* de $\\theta$, siendo $\\theta$ la probabilidad de que un paciente en planta ingrese en la UCI. \n",
    "\n",
    "En realidad, en este problema, **no** es necesario utilizar Monte Carlo. \n",
    "\n",
    "Cuando la distribución *a priori* $\\pi(\\theta)$ es una distribución $Beta (\\theta|\\alpha, \\beta)$ y la función de verosimilitud $\\pi(x| \\theta)$ está dada por (5), la distribución *a posteriori* $\\pi(\\theta| x)$  tiene una *expresión cerrada*.\n",
    "En este caso $\\pi(\\theta| x)$ es también una distribución $Beta$ (se dice que ambas son *conjugadas a priori*) de parámetros $\\alpha'$ y $\\beta'$ donde $\\alpha' = \\alpha +k$ y $\\beta'=\\beta + (n-k)$. \n",
    "Es decir, el parámetro $\\alpha$ de la distribución a priori se incrementa en $k$ (el número de éxitos del experimento) y el parámetro $\\beta$ en $n-k$ (el número de fracasos).\n",
    "\n",
    "En la gráfica siguiente se representan las distribuciones *a priori, a posteriori* y *verosimilitud* para los valores propuestos por el problema, $ \\pi(\\theta) = Beta(\\theta|\\alpha=5,\\beta=10)$ $n=20$ y $k=1$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected probability a priori: 0.333 \n",
      "Expected probability a posterior: 0.171\n",
      "Maximum likelihood: 0.050\n",
      "Experimento: \n",
      " Total pacientes:20  UCI:1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, x_size)\n\u001b[0;32m---> 38\u001b[0m pi_prior \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mpdf(x, a, b)\n\u001b[1;32m     39\u001b[0m pi_posterior \u001b[38;5;241m=\u001b[39m  scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mpdf(x, a_posterior, b_posterior)\n\u001b[1;32m     40\u001b[0m verosi \u001b[38;5;241m=\u001b[39m likelihood(x, exitos_exp, n_exp) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a priori knowledge (Beta distribution)\n",
    "a, b = 5, 10                                                   # alpha y beta de la distribucion Beta\n",
    "mu = lambda a_, b_ : a_ / (a_ + b_)                            #  mean Beta distribution\n",
    "sigma2 = lambda a_, b_: (a_*b_) / (((a_+b_)**2) * (a_+b_+1))   # Variance Beta distribution\n",
    "\n",
    "# Experiment results\n",
    "n_exp = 20\n",
    "exitos_exp = 1  \n",
    "\n",
    "fracasos_exp = n_exp - exitos_exp  # valor 0\n",
    "\n",
    "# Posterior\n",
    "a_posterior =  a + exitos_exp \n",
    "b_posterior = b + fracasos_exp\n",
    "mu_posterior = mu(a_posterior, b_posterior)\n",
    "\n",
    "print(f'Expected probability a priori: {mu(a, b):.3f} ')\n",
    "print(f'Expected probability a posterior: {mu(a_posterior, b_posterior):.3f}')\n",
    "print(f'Maximum likelihood: {exitos_exp / n_exp:.3f}')\n",
    "print(f'Experimento: \\n Total pacientes:{n_exp}  UCI:{exitos_exp}')\n",
    "\n",
    "\n",
    "# Verosimilitud\n",
    "likelihood_prop = lambda theta, k, n: np.power(theta, k) * np.power(1-theta, n-k)\n",
    "\n",
    "def likelihood(theta, k, n):\n",
    "    '''Likelihood pdf (likelihood_prop lambda function normalized) '''\n",
    "    int_num = integrate.quad(likelihood_prop, a=0, b=1, args=(k, n))  \n",
    "    y = likelihood_prop(theta, k, n) / int_num[0]\n",
    "    return y\n",
    "\n",
    "\n",
    "#Polt a priori,  posteriori and likelihood\n",
    "x_size = 1000\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "\n",
    "x = np.linspace(0, 1, x_size)\n",
    "pi_prior = scipy.stats.beta.pdf(x, a, b)\n",
    "pi_posterior =  scipy.stats.beta.pdf(x, a_posterior, b_posterior)\n",
    "verosi = likelihood(x, exitos_exp, n_exp) \n",
    " \n",
    "ax.plot (x, pi_prior, 'b-', lw=1, alpha=0.6, label=r'prior, $\\pi(\\theta)$') \n",
    "ax.plot (x, pi_posterior, 'r-', lw=1, alpha=0.6, label=r'posterior, $\\pi(\\theta | x)$') \n",
    "ax.plot (x, verosi, 'g-', lw=1, alpha=0.6, label=r'likelihood, $\\pi(x|\\theta)$') \n",
    "ax.set_xlabel (r'$\\theta$, prob paciente planta --> UCI')\n",
    "\n",
    "ax.legend(loc='best', frameon=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa la distribución a *posteriori* es un compromiso entre la distribución a priori (el conocimiento del que dispongo **antes** de realizar el experimento) y la *verosimilitud* (el conocimiento que me aporta *exclusivamente* el resultado del experimento).\n",
    "\n",
    "En el caso particular en que $\\pi(\\theta)$ fuese aproximadamente constante sobre el rango de valores de $\\theta$ en los que la verosimilitud no fuese nula, la _posteriori_ sería simplemente la función de verosimilitud. En este caso se dice que $\\pi(\\theta)$ es **no informativa**.\n",
    "\n",
    "**Ejercicio:** Analiza el caso en $\\pi(\\theta)$ fuese una distribución $Beta(\\alpha=1, \\beta=1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el problema estamos interesados en hallar el valor esperado de la v.a $\\theta$ para las distribuciones *a priori* y *a posteriori*. O lo que es lo mismo, debemos hallar el valor esperado de una v.a aleatoria que se distribuye según una $Beta (\\theta |\\alpha, \\beta)$ de parámetros conocidos. Se puede demostrar que\n",
    "\n",
    "$$\n",
    "\\mu = E[\\theta] := \\int_0^1 \\theta \\; B(\\theta | \\alpha, \\beta) \\; d\\theta = \\frac{\\alpha}{\\alpha + \\beta}\n",
    "$$\n",
    "\n",
    "**¿Qué ocurre cuando aumenta el tamaño del experimento?**\n",
    "\n",
    "En la gráfica siguiente se ha incrementado la muestra del experimento, $n=100$, pero manteniendo el ratio $k/n=0.05$ del experimento original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# pi_a priori knowledge\n",
    "a, b = 5, 10\n",
    "mu = lambda a_, b_ : a_ / (a_ + b_)                               # Valor esperado distribucion Beta\n",
    "sigma2 = lambda a_, b_: (a_*b_)/( ((a_+b_)**2) * (a_+b_+1)  )     # Varianza distribución Beta\n",
    "\n",
    "# Experiment results\n",
    "MUL = 5\n",
    "n_exp = 20*MUL                                                    # Éxitos experimento\n",
    "exitos_exp = 1*MUL                                                # Total en experimento\n",
    "fracasos_exp = n_exp - exitos_exp                               \n",
    "\n",
    "# Posterior\n",
    "a_posterior =  a + exitos_exp           \n",
    "b_posterior = b + fracasos_exp\n",
    "mu_posterior = mu(a_posterior, b_posterior)                       # valor esperadp\n",
    "\n",
    "\n",
    "print(f'Expected probability a priori: {mu(a, b):.3f} ')\n",
    "print(f'Expected probability a posterior: {mu(a_posterior, b_posterior):.3f}')\n",
    "print(f'Maximum likelihood: {exitos_exp / n_exp:.3f}')\n",
    "print(f'Experimento: \\n Total pacientes:{n_exp}  UCI:{exitos_exp}')\n",
    "\n",
    "# Plot a priori,  posteriori and likelihood\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pi_prior = scipy.stats.beta.pdf (x, a, b)\n",
    "pi_posterior =  scipy.stats.beta.pdf (x, a_posterior, b_posterior)\n",
    "verosi = likelihood (x, exitos_exp, n_exp) \n",
    " \n",
    "ax.plot (x, pi_prior, 'b-', lw=1, alpha=0.6, label=r'prior, $\\pi(\\theta)$') \n",
    "ax.plot (x, pi_posterior, 'r-', lw=1, alpha=0.6, label=r'posterior, $\\pi(\\theta | x)$') \n",
    "ax.plot (x, verosi, 'g-', lw=1, alpha=0.6, label=r'likelihood, $\\pi(x|\\theta)$') \n",
    "ax.set_xlabel (r'$\\theta$, prob paciente planta --> UCI')\n",
    "\n",
    "ax.legend(loc='best', frameon=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Algunas consecuencias interesantes que se derivan de la expresión analítica de $\\pi(\\theta | x)$:\n",
    "\n",
    "* Al ser $\\pi(\\theta|x)$ también una distribución Beta, el **valor esperado de $\\theta$ a posteriori**, i.e., después de observar el resultado del experimento, es  \n",
    "$$\n",
    "\\mu_{\\text{posterior}} = E \\left[ \\theta | x \\right]  \n",
    "= \\frac{\\alpha'}{\\alpha' + \\beta'} = \\frac{\\alpha + k}{\\alpha +k + \\beta + n - k} =   \\frac{\\alpha + k}{\\alpha + \\beta + n}\n",
    "$$\n",
    "  Teniendo en cuenta que el **valor esperado de la distribución a priori** $\\pi(\\theta)$ es:\n",
    "$$\n",
    "\\mu_{\\text{priori}}=  E \\left[ \\theta \\right]   = \\frac{\\alpha}{\\alpha + \\beta}\n",
    "$$\n",
    "y el **valor de $\\theta$ para el que la verosimilitud es máxima** $\\theta_{MLE} = k/n$ (ver _Recordatorio_ siguiente), podemos expresar el valor esperado a posteriori como la media ponderada del valor esperado de\n",
    "nuestras creencias a priori y la estimación de máxima verosimilitud\n",
    "$$\n",
    "\\mu_{\\text{posterior}} = \\frac{\\alpha + k}{\\alpha + \\beta + n } =\n",
    "\\frac{\\alpha + \\beta}{\\alpha + \\beta + n } \\; \\mu_{\\text{priori}} +\n",
    "\\frac{n}{\\alpha + \\beta + n } \\; \\theta_{MLE}\n",
    "$$\n",
    "\n",
    "* Cuando el número de pacientes del experimento es muy grande, $n, k \\to \\infty$, $\\mu_{\\text{posterior}}$ converge al valor de máxima verosimilitud (MLE) $k/n$. Es decir, cuando $n \\to \\infty$, **el *conocimiento a priori* es irrelevante frente a la información que aporta el experimento.** \n",
    "\n",
    "* **La *incertidumbre* en torno al valor esperado $\\mu_{\\text{posterior}}$ decrece con $n \\to \\infty$** \n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\lim_{n \\to \\infty} \\frac{ \\alpha' \\beta'}{ (\\alpha' + \\beta')^2 (\\alpha' + \\beta' +1) } = \\frac{k n -k^2}{n^3} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una introducción _breve_ a distribuciones conjugadas https://halweb.uc3m.es/esp/Personal/personas/causin/esp/2012-2013/SMB/Tema6.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "<div class=\"alert-success\">\n",
    "\n",
    "**Recordatorio:**    \n",
    "\n",
    "El valor máximo de la verosimilitud MLE de una v.a $\\theta$ es el valor de $\\theta$ para el cúal la función de verosimilitud es máxima\n",
    "$$\n",
    "\\theta_{MLE} = \\text{argmax}_{\\theta} \\pi(x | \\theta)\n",
    "$$\n",
    "    \n",
    "Habitualmente se calcula maximizando el logarítmo de $\\pi(x|\\theta)$\n",
    "    $$\n",
    "    \\frac{\\partial}{\\partial \\theta} log (\\pi (x | \\theta) ) = 0\n",
    "    $$\n",
    "\n",
    "Para este problema, en el que $\\pi(x| \\theta)$ está dada por la ecuación (5) \n",
    "    $$\n",
    "     \\frac{\\partial }{\\partial \\theta}\\left( k log (\\theta ) + (n-k) \\log(1-\\theta) \\right) = 0\n",
    "    $$\n",
    "    se obtiene $\\theta_{MLE}$ = k/n  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulación  Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---- Monte Carlo -------\n",
    "\n",
    "def media_interv_acumulada(x, alpha = 0.05):\n",
    "    '''Calcula el valor estimado y la dispersión de una muestra \n",
    "    {x_0, x_1, ... x_n} de tamaño n utilizando para ello las i= 1... n muestras'''\n",
    "    z_alpha = scipy.stats.norm.ppf(1 - (alpha / 2) )    \n",
    "    n = x.size\n",
    "    size =  np.arange (start=1, stop=n+1, step=1)\n",
    "    \n",
    "    # media acumulada\n",
    "    media = np.cumsum (x) / size\n",
    "    \n",
    "    # Varianza muestral, s2\n",
    "    x2 = x*x\n",
    "    s2 = np.cumsum (x2) / size - media*media\n",
    "    # varianza estimador\n",
    "    sigma2 = s2 /  size\n",
    "    \n",
    "    #intervalo de confianza\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    dx = z_alpha * sigma\n",
    "    \n",
    "    return (media, dx)\n",
    "\n",
    "def prop_error(x, y, dx, dy):\n",
    "    '''Error propoagation (sobreestimado) '''\n",
    "    z = x/y\n",
    "    dz = (np.abs(dx/x) + np.abs(dy/y) )*z\n",
    "    return (z, dz)\n",
    "\n",
    "\n",
    "def do_ratio(x, y, alpha=0.05):\n",
    "    num = media_interv_acumulada(x, alpha)\n",
    "    den = media_interv_acumulada(y, alpha)\n",
    "    theta_est = prop_error (num[0], den[0], num[1], den[1])\n",
    "    \n",
    "    return theta_est    \n",
    "\n",
    "######################## MONTE CARLO ######################\n",
    "\n",
    "np.random.seed(124)\n",
    "size_mc = 7000\n",
    "\n",
    "a, b = 5, 10\n",
    "sample_mc = st.beta.rvs (size=size_mc, a=a, b=b)\n",
    "\n",
    "eval_num =  sample_mc * likelihood_prop(sample_mc, exitos_exp, n_exp) \n",
    "eval_den =  likelihood_prop(sample_mc, exitos_exp, n_exp) \n",
    "\n",
    "alpha = 0.22 #confidence interval\n",
    "theta_est = do_ratio (eval_num,eval_den, alpha=alpha)\n",
    "print(f'Expected probability a posteriori MC: {theta_est[0][-1]:.6f} +- {theta_est[1][-1]:.3f}')\n",
    "print(f'Confidence interval \\u03B1 = {alpha}')\n",
    "print(f'Experimento: \\n Total pacientes:{n_exp}  UCI:{exitos_exp}')\n",
    "\n",
    "\n",
    "# Plot MC\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "\n",
    "x = np.arange(1, len(theta_est[0])+1)\n",
    "y =  theta_est[0]\n",
    "y_sup = theta_est[0] + theta_est[1]\n",
    "y_inf = theta_est[0] - theta_est[1]\n",
    "\n",
    "desde = 10\n",
    "ax.plot (x[desde :], y[desde :], alpha=0.8)\n",
    "ax.set_xlabel (r'Monte Carlo sample size')\n",
    "ax.set_ylabel (r'$\\widehat \\mu_{posteriori}$')\n",
    "ax.fill_between(x[desde:], y_inf[desde:], y_sup[desde:], alpha= 0.2 )\n",
    "\n",
    "# resultado teórico\n",
    "ax.hlines( mu(a_posterior, b_posterior), 0, len(theta_est[0]), lw=0.7, colors=\"red\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "<div class=\"alert-warning\">\n",
    "\n",
    "**Propogación del error**\n",
    "\n",
    "Supongamos que $Z$ es el cociente de dos v.a $Z= X/Y$, si estimamos el valor esperado de $\\mu_Z$ por ejemplo mediante \n",
    "$$\n",
    "\\widehat{\\mu_z} = \\frac{\\sum_{i=1}^n x_i}{\\sum_{i=1}^n y_i}   \n",
    "$$\n",
    "donde $\\{x_0, x_1, \\ldots, x_n \\}$ y $\\{y_0, y_1, \\ldots, y_n \\}$ son muestras de $X$ e $Y$ respectivamente ¿cómo estimar la varianza de $\\widehat{\\mu_z}$?\n",
    "\n",
    "Podemos interpretar $x$ e $y$ como una *medida con un error asociado* ($x\\pm \\delta x$, $y\\pm \\delta y$) y estimar el error de la medida de $z$  en el *peor caso*\n",
    "\n",
    " \\begin{align}\n",
    "(z + \\delta z) (y + \\delta y) &= x + \\delta x \\\\\n",
    "z \\  y + z \\,   \\delta y + y \\,  \\delta z + \\delta z \\; \\delta y &= x + \\delta x \\\\\n",
    "  \\end{align}\n",
    "Si en la ecuación anterior se dividen los dos miembros por $x$ y asumiendo *el peor caso (los errores se suman)*\n",
    "$$\n",
    "\\frac{\\delta z}{z} = \\frac{\\delta x}{x} + \\frac{\\delta y}{y}  \n",
    "$$\n",
    "\n",
    "</div>\n",
    "\n",
    "* **Cuestiones**:\n",
    "\n",
    "   * ¿Por que se debe utilizar la misma muestra de $\\theta$ en el numerador y denominador para estimar  $\\mu_{posterior}$? \n",
    "   * ¿Por que a la hora de hacer la simulación de M.C hemos podido utilizar una función sin normalizar proporcional a $\\pi(x | \\theta)$ eq. (5) y **no** $\\pi(x | \\theta)$? \n",
    " \n",
    "* **Importante:** \n",
    "\n",
    "    * Fíjate que el metodo de Monte Carlo nos ha permitido calcular el valor esperado de $\\theta$ a posteriori **sin** necesidad de disponer de una muestra de la distribución a posteriori $\\pi(\\theta|x)$.\n",
    "  \n",
    "    * Siempre debes validar tu simulación: \n",
    "        * En este caso puedes *validar* tu simulación frente al resultado teórico conocido ¿Se comporta correctamente tu estimación cuando aumenta el tamaño del experimento?\n",
    "        * ¿Cómo de fiable es la estimación del error que hemos hecho? Discute que valor \n",
    "        de $z_{\\alpha/2}$ es apropiado.\n",
    "\n",
    "* **....y algo mas**\n",
    "\n",
    "    * Supón que no se dispone de un generador de números aleatorios para la distribución a priori (porqué o bien no dispones de un algoritmo o este es muy ineficaz) ¿Podrías estimar $\\mu_{posterior}$? \n",
    "    Estima el valor de $\\mu_{posterior}$ **sin** utilizar el generador de una muestra de Beta (por ejemplo utiliza una distribución $\\mathcal{U}(0,1)$). Discute el intervalo de confianza de la estimación.    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(124)\n",
    "\n",
    "# Estimación de del valor esperado de la distribución a posteriori\n",
    "# Simulación de Monte Carlo utilizando una distribución uniforme\n",
    "\n",
    "size_mc = 7000\n",
    "sample_mc = scipy.stats.uniform.rvs (size=size_mc)\n",
    "dist =  scipy.stats.beta.pdf (sample_mc, a=a, b=b)\n",
    "\n",
    "eval2_num =  sample_mc * likelihood_prop (sample_mc, exitos_exp, n_exp) * dist \n",
    "eval2_den =  likelihood_prop (sample_mc, exitos_exp, n_exp) * dist\n",
    "\n",
    "theta_est = do_ratio (eval2_num,eval2_den, alpha=0.05)\n",
    "print(f'Expected probability a posteriori MC: {theta_est[0][-1]:.6f} +- {theta_est[1][-1]:.3f}')\n",
    "print(f'Confidence interval \\u03B1 = {alpha}')\n",
    "print(f'Experimento: \\n Total pacientes:{n_exp}  UCI:{exitos_exp}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "<div class=\"alert-warning\">\n",
    "\n",
    "\n",
    "Estimar empíricamente la función de densidad de probabilidad *a posteriori* $\\pi(\\theta | x)$ del ejercicio anterior y validarla con el resultado teórico. Discutir los resultados \n",
    "</div>\n",
    "\n",
    "### Introducción\n",
    "\n",
    "En el ejercicio anterior estimamos, utilizando Monte Carlo, el valor esperado de $\\theta$ *a posteriori*, es decir, una vez realizado el experimento. Recuerda que lo estimamos **sin** necesidad de conocer la distribución a posteriori  $\\pi(\\theta | x)$. Para ello utilizamos el Teorema de Bayes. \n",
    "Además validamos nuestra estimación con la solución analítica.  \n",
    "\n",
    "Ahora nos planteamos algo mas ¿podemos estimar la distribución *a posteriori* $\\pi(\\theta | x)$?. Para ello necesitaríamos: (i) generar una muestra de $\\pi(\\theta | x)$ y (ii) a partir de la muestra estimar empíricamente la distribución.  Para generar la muestra de la variable aleatoria utilizaremos un **método de aceptación y rechazo**. La estimación de la distribución a prtir de la muetra la realizaremos del modo mas _naive_ posibe, utilizando histogramas. Validaremos nuestros resultados con la solución analítica.\n",
    "\n",
    "### Planteamiento de Monte Carlo\n",
    "\n",
    "El algoritmo consistirá en generar una muestra $\\{\\theta_0, \\theta_1, \\theta_2, \\cdots, \\theta_n\\}$ de la distribución *a priori* $\\pi(\\theta)$ y aceptar como valores de la distribución *a psoteriori* $\\pi(\\theta | x)$ aquellos $\\theta_i$  que satisfagan un determinado criterio de aceptación/rechazo.\n",
    "\n",
    "* Un algoritmo y criterio *tentativo* podría ser:\n",
    "\n",
    ">1. Generar una muestra $\\{\\theta_0, \\theta_1, \\theta_2, \\cdots, \\theta_n\\}$ de la distribución a priori $\\pi(\\theta)$ \n",
    ">1. Aceptar $\\theta_i$ con probabilidad\n",
    ">$$\n",
    "p = \\frac{ \\pi(\\theta_i | x) }{c \\cdot \\pi(\\theta_i) }\n",
    "$$\n",
    "donde $c$ es, como de costumbre, una constante tal que para todo $\\theta$, $p \\in [0, 1]$. Para aplicar el criterio anterior podríamos generar una muestra $\\{u_0, u_1, u_2, \\cdots, u_n\\}$ de la distribución uniforme $U(0,1)$ y aceptar $\\theta_i$ si  $u_i <  \\frac{ \\pi(\\theta_i | x) }{c \\cdot \\pi(\\theta_i) }$ \n",
    "\n",
    "   Es decir, tratamos de aplicar el mismo algoritmo de aceptación/rechazo visto en clase. El problema con este *criterio tentativo* es evidente. Para aplicarlo necesitamos: (i) evaluar $\\pi(\\theta | x)$ en $\\theta_i$ y (ii) calcular previamente el valor de la constante $c$. Pero ¿Cómo podemos hacerlo si precisamente desconocemos la distribución  $\\pi(\\theta | x)$?¿Qúe podemos hacer? Recurrir al Teorema de Bayes.\n",
    "   \n",
    "* Deducción del criterio de aceptación / rechazo. Por el teorema de Bayes sabemos   \n",
    "$$\n",
    " \\frac{ \\pi(\\theta | x) }{ \\pi(\\theta) } = \n",
    " \\frac{ \\pi(x | \\theta) }\n",
    "{ \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta}  \n",
    "$$\n",
    "\n",
    "   pero, en vez de utilizar el lado izquierdo de la ecuación anterior para evaluar la probabilidad $p$ de aceptar $\\theta_i$ como en la ecuación (21), utilizaremos el miembro derecho de (22). Sin embargo, aun nos falta estimar el valor de $c$. Necesitamos *normalizar* el cociente $\\frac{ \\pi(x | \\theta) }\n",
    "{ \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta} $ por una constante $c$ para que su valor este comprendido en el intervalo $[0, 1]$. Pero esto no es complicado. \n",
    "Sabemos que  *necesariamente*  $\\frac{ \\pi(x | \\theta) }\n",
    "{ \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta} $  está acotado: el numerador es una función densidad de probabilidad y el denominador es una constante, no depende de $\\theta$. Es decir que\n",
    "$$\n",
    "\\frac{ \\pi(x | \\theta) }\n",
    "{ \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta}  \\leq \n",
    "\\frac{ \\text{argmax}_{\\theta} \\left( \\pi(x | \\theta) \\right) }\n",
    "{ \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta} = c\n",
    "$$\n",
    "\n",
    "   donde  $\\text{argmax}_{\\theta} \\left( \\pi(x | \\theta) \\right)$ representa al valor máximo de la verosimilitud $\\pi(x | \\theta)$. Es decir, ni siquiera necesitamos calcular la integral $\\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta$ ya que cuando dividamos la ecuación (22) por $c$ se nos va a cancelar!!!\n",
    "   \n",
    "Además sabemos que la función de verosimilitud alcanza su máximo cuando $\\theta $ es el *valor máximo de verosimilitud* $\\theta_{MLE} = k/N$, siendo $N$ el número total de pacientes y $k$ el número de pacientes que ingresan en la UCI. Recopilando todo: \n",
    "\n",
    "\n",
    "* Algoritmo final para obtener una muestra de $\\pi(\\theta | x)$\n",
    ">\n",
    ">1. Calcular $a =  \\text{argmax}_{\\theta} \\left( \\pi(x | \\theta) \\right) $\n",
    ">1. Generar una muestra $\\{\\theta_0, \\theta_1, \\theta_2, \\cdots, \\theta_n\\}$ de la distribución a priori $\\pi(\\theta)$ \n",
    ">1. Aceptar $\\theta_i$ con probabilidad\n",
    "$$\n",
    "p =   \\frac{ \\pi(x | \\theta) }\n",
    "{c \\cdot \\int_{-\\infty}^{\\infty}  \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta}   =  \n",
    "\\frac{  \\pi(x | \\theta) }{a}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados simulación Monte Carlo\n",
    "\n",
    "En la siguiente gráfica se muestra un histograma con la estimación empírica de la función de densidad de probabilidad a posteriori $\\pi(\\theta | x)$ junto con el resultado teórico (en azul distribución Beta de parámetros $a$ y $b$ conocidos).\n",
    "\n",
    "La eficiencia del algoritmo de aceptación/rechazo ha sido del $6.52\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple\n",
    "\n",
    "def aceptacion_rechazo(sample: np.array, c: float, f: Callable, args=()) -> np.array:\n",
    "    f_c = f(sample, *args) / c\n",
    "    u = st.uniform.rvs(size = len(f_c))\n",
    "    return sample[u < f_c]\n",
    "\n",
    "def likelihood_prop(theta: np.array, k: int, n: int) -> np.array: \n",
    "    ''' Función de verosimilitud sin normalizar '''\n",
    "    return np.power(theta, k) * np.power((1 - theta), (n - k))\n",
    "\n",
    "\n",
    "# a priori probability Beta(a, b)\n",
    "priori = st.beta\n",
    "a, b = 5, 10                                   # parametro alpha y beta\n",
    "\n",
    "# Experimento\n",
    "np.random.seed(124)\n",
    "k = 1                                          # exitos\n",
    "n = 20                                         # totales \n",
    "theta_MLE = k / n                              # Máxima verosimilitud\n",
    "\n",
    "###### Simulación Monte Carlo\n",
    "size_mc = 10**5\n",
    "\n",
    "sample_mc = priori.rvs(size = size_mc, a = a, b = b)\n",
    "c = likelihood_prop(theta_MLE, k, n)            # máximo para theta = MLE\n",
    "sample_post = aceptacion_rechazo(sample_mc, c, likelihood_prop, args=(k, n))\n",
    "\n",
    "efficiency = len(sample_post) / size_mc\n",
    "print(f'Efficiency= {efficiency}')\n",
    "\n",
    "####### Validación modelo ################\n",
    "''' H0: La muestra es compatible con una distribución Beta de parámetros\n",
    "    alpha = a_posterior y beta = b_posterior\n",
    "'''\n",
    "H0_distribution = st.beta             \n",
    "a_posterior =  a + k\n",
    "b_posterior = b + (n-k)\n",
    "H0_args = (a_posterior, b_posterior)\n",
    "\n",
    "#1...  Kolmogorov\n",
    "print(st.kstest(sample_post,  H0_distribution.cdf, args=H0_args))\n",
    "\n",
    "#2.... Chi-square\n",
    "# get the counts and the bins\n",
    "bins = 30\n",
    "counts, edges  = np.histogram(sample_post, bins=bins, density=False)\n",
    "\n",
    "# merging bins with low counts\n",
    "low_counts = 6\n",
    "c, e = combine_edges (counts, edges, low_counts)\n",
    "\n",
    "# get the bins probabilities\n",
    "prob = get_bin_probabilities(H0_distribution, H0_args, edges)\n",
    "\n",
    "print(\"Chi-square test:\")\n",
    "print(st.chisquare(c, f_exp= sum(c) * prob))\n",
    "\n",
    "\n",
    "########### Plot ###########################\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,  figsize=(10, 3))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pi_posterior =  H0_distribution.pdf(x, *H0_args)\n",
    "\n",
    "ax.plot (x, pi_posterior, label= r'$\\pi(\\theta|x)$ pdf')                           # Teorica\n",
    "ax.hist(sample_post, bins=bins, density=True, alpha=0.4, label = 'Estimated')      # Estimacion\n",
    "ax.legend(loc = 'best', frameon = False)\n",
    "ax.set_xlabel (r'$\\theta$, probability move to UCI')\n",
    "ax.set_ylabel (r'$\\pi(\\theta | x)$, a posteriori pdf')\n",
    "ax.set_title (f'Monte Carlo simulation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Por qué se ha utilizado la función de verosimilitud sin normaslizar en vez de la normalizada?\n",
    "* ¿Por que es tan baja la tasa de eficiencia? La tasa de eficiencia es un reflejo del solapamiento entre la distribución a priori $\\pi(\\theta)$, la distribución de la que se muestrea, y la distribución a posteriori $\\pi(\\theta|x)$. Cuanto mas alejada esté la primera de la segunda, mayor será el porcentaje de muetras rechazadas. Recordad que $\\sigma^2 \\to 0$ de la distribución a posteriori cuando $N \\to \\infty$\n",
    "\n",
    "* ¿Como mejorar la tasa de eficiencia? Es posible realizar un Monte Carlo evolutivo cuando el conocimiento del experimento se incorpora paulatinamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencia**\n",
    "\n",
    "Simulación, métodos y aplicaciones, 2 edición. D. Rios Insúa et al. Ra-Ma Editorial (2008), p. 188"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
